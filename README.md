# project-in-LangChain
Project using LangChain to mitigate hallucination in Large Laguage Model 

Project developed for my experimental thesis, I have devised two similar methods to try to mitigate
the problem of hallucination that plagues contemporary Large Language Models (LLM).
I have incorporated a way to create a simple interface using Gradio. 

Examples were conducted on both data that was known (Attention is all you need paper)
and data that was unknown (Curriculum Vitae and Sources of Hallucination by Large Language Models on Inference Tasks paper).

To use this project, it is necessary to insert your own API key.
